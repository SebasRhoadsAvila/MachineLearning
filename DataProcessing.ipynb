{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data set with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('C:/Users/Sebas/Desktop/DataSets/DataSetsPython/data1.csv')\n",
    "x = dataset.iloc[:,:-1].values   #independent variables\n",
    "y = dataset.iloc[:,-1].values    #Dependent variable\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"iloc\" command stands for index location, and \":\" idicates range. Range includes lower limit whereas excludes the upper limit. The \"-1\" stands for the last column, it is excluded in the x dataset and included exclusively in the Y dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution for Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country      0\n",
      "Age          1\n",
      "Salary       1\n",
      "Purchased    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = dataset.isnull().sum()\n",
    "print(missing_values) #Number of missing values on each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean') #object/strategy to deal with missing values\n",
    "imputer.fit(x[:,1:3])    #\"fit\" method use to apply the object to the columns specified\n",
    "x[:,1:3]=imputer.transform(x[:,1:3]) #\"transform\" method to update our columns\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of deleting the rows containing missing values, we simply apply an object that replaces the missing value for the average value from each column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],\n",
    "                       remainder='passthrough')\n",
    "x = np.array(ct.fit_transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independent variable: First, we change the 3 countries into categorical data. The \"country\" column was transform into 3 new columns, each one takes the value 1 for its respective country. \n",
    "Usefull to directly transform a multi-categorical label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y=le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependent variable: We changed the \"yes/no\" column for a \"1/0\" column. \n",
    "Usefull to directly enncode a binary outcome from a two classes label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the necessary libraries\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "# Load the dataset\n",
    "titanic_dataset = pd.read_csv('C:/Users/Sebas/Desktop/DataSets/DataSetsPython/titanic.csv')\n",
    "titanic_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 ... 'A/5 21171' 7.25 nan]\n",
      " [1.0 0.0 1.0 ... 'PC 17599' 71.2833 'C85']\n",
      " [1.0 0.0 0.0 ... 'STON/O2. 3101282' 7.925 nan]\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 'W./C. 6607' 23.45 nan]\n",
      " [0.0 1.0 1.0 ... '111369' 30.0 'C148']\n",
      " [0.0 1.0 0.0 ... '370376' 7.75 nan]]\n"
     ]
    }
   ],
   "source": [
    "# Identify the categorical data\n",
    "categorical_features = ['Sex', 'Embarked', 'Pclass']\n",
    "# Implement an instance of the ColumnTransformer class\n",
    "ct = ColumnTransformer( transformers=[ ('encoder', OneHotEncoder(), categorical_features) ],remainder='passthrough' )\n",
    "# Apply the fit_transform method on the instance of ColumnTransformer\n",
    "X = ct.fit_transform(titanic_dataset)\n",
    "# Convert the output into a NumPy array\n",
    "X = np.array(X)\n",
    "# Use LabelEncoder to encode binary categorical data\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(titanic_dataset['Survived'])\n",
    "# Print the updated matrix of features and the dependent variable vector\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 0 0 0 1\n",
      " 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0\n",
      " 1 0 0 0 1 1 0 1 1 0 1 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0\n",
      " 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0\n",
      " 0 0 1 1 1 1 0 1 0 1 1 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0\n",
      " 0 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 1 1 1\n",
      " 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 1 0 0 1 0 1 0 0 1 0 0 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0\n",
      " 1 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 1 0 1 1 0 0 1 1\n",
      " 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 0 0 0 1\n",
      " 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 1 0 0 0 0 1 0\n",
      " 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0\n",
      " 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 0 0 1\n",
      " 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
       "        [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
       "        [1.0, 0.0, 0.0, 44.0, 72000.0],\n",
       "        [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "        [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "        [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
       "        [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
       "        [1.0, 0.0, 0.0, 35.0, 58000.0]], dtype=object),\n",
       " array([[0.0, 1.0, 0.0, 30.0, 54000.0],\n",
       "        [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object),\n",
       " array([0, 1, 0, 0, 1, 1, 0, 1]),\n",
       " array([0, 1]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 30.0 54000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scalling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
    "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the same scaler from the feature training set for the feature test set. We can't make a new one, otherwise the model would be different.\n",
    "\n",
    "Also, it is worth mentioning that we didn't apply feature scaling to the dependent variable because it already had the values 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
      " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
      " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
      " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
      " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
      " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
      " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
      " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
      " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_Acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Ash_Alcanity</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_Phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_Intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Customer_Segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic_Acid   Ash  Ash_Alcanity  Magnesium  Total_Phenols  \\\n",
       "0      14.23        1.71  2.43          15.6        127           2.80   \n",
       "1      13.20        1.78  2.14          11.2        100           2.65   \n",
       "2      13.16        2.36  2.67          18.6        101           2.80   \n",
       "3      14.37        1.95  2.50          16.8        113           3.85   \n",
       "4      13.24        2.59  2.87          21.0        118           2.80   \n",
       "..       ...         ...   ...           ...        ...            ...   \n",
       "173    13.71        5.65  2.45          20.5         95           1.68   \n",
       "174    13.40        3.91  2.48          23.0        102           1.80   \n",
       "175    13.27        4.28  2.26          20.0        120           1.59   \n",
       "176    13.17        2.59  2.37          20.0        120           1.65   \n",
       "177    14.13        4.10  2.74          24.5         96           2.05   \n",
       "\n",
       "     Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  Color_Intensity   Hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     OD280  Proline  Customer_Segment  \n",
       "0     3.92     1065                 1  \n",
       "1     3.40     1050                 1  \n",
       "2     3.17     1185                 1  \n",
       "3     3.45     1480                 1  \n",
       "4     2.93      735                 1  \n",
       "..     ...      ...               ...  \n",
       "173   1.74      740                 3  \n",
       "174   1.56      750                 3  \n",
       "175   1.56      835                 3  \n",
       "176   1.62      840                 3  \n",
       "177   1.60      560                 3  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_dataset = pd.read_csv('C:/Users/Sebas/Desktop/DataSets/DataSetsPython/wine.csv') # watch out for delimiters (delimiter=';')\n",
    "# Separate features and target\n",
    "wx = wine_dataset.iloc[:,:-1].values   \n",
    "wy = wine_dataset.iloc[:,-1].values   \n",
    "\n",
    "# Split the dataset into an 80-20 training-test set\n",
    "wX_train, wX_test, wy_train, wy_test = train_test_split(wx, wy, test_size=0.2, random_state=42)\n",
    "\n",
    "wine_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.66529275 -0.60840587  1.21896194 ... -1.65632857 -0.87940904\n",
      "  -0.24860607]\n",
      " [-0.54952506  2.7515415   1.00331502 ... -0.58463272 -1.25462095\n",
      "  -0.72992237]\n",
      " [-0.74531007 -1.14354109 -0.93750727 ...  0.35845962  0.2462267\n",
      "  -0.24860607]\n",
      " ...\n",
      " [ 1.714239   -0.44172441  0.06884503 ...  1.04434496  0.56585166\n",
      "   2.69572196]\n",
      " [-0.35374006 -0.7399965  -0.36244882 ...  0.01551695 -0.74044166\n",
      "  -0.79631083]\n",
      " [-0.78201975  0.06709269  0.35637426 ... -0.67036839  1.09392769\n",
      "  -0.98551793]]\n",
      "[[ 8.08733375e-01  6.37318741e-01  7.15785791e-01 -1.24128036e+00\n",
      "   1.06556722e+00  6.46636689e-01  1.02724237e+00 -1.54932094e+00\n",
      "   8.93605295e-02  1.82522280e-02  1.55169482e-02  1.06613421e+00\n",
      "   3.65487151e-01]\n",
      " [ 1.50621744e+00  1.46195334e+00  2.84491948e-01 -1.66513218e-01\n",
      "   7.23080697e-01  8.82684015e-01  6.47480801e-01 -5.32234717e-01\n",
      "  -6.15594759e-01  7.85270273e-02 -3.70293555e-01  1.02444400e+00\n",
      "   1.14555151e+00]\n",
      " [-6.00625639e-02  3.82910194e-01  1.21896194e+00  4.43489751e-01\n",
      "  -3.04378866e-01 -1.17879597e+00 -1.50117016e+00  1.26722552e+00\n",
      "  -1.47529633e+00 -1.97014913e-01 -7.98971892e-01 -3.93023224e-01\n",
      "  -4.47771435e-01]\n",
      " [ 9.18862438e-01 -7.66314624e-01  1.21896194e+00  8.79206158e-01\n",
      "   3.81076551e-02  1.11873134e+00  1.24710433e+00 -6.10472119e-01\n",
      "   1.32733079e+00  2.76572797e-01  1.00147712e+00  1.62846276e-01\n",
      "   1.82603318e+00]\n",
      " [-7.45310065e-01 -1.05581401e+00 -1.58444804e+00  3.68211048e-02\n",
      "  -1.53733034e+00 -2.81816127e-01 -2.11135044e-03 -7.66946921e-01\n",
      "  -9.76669419e-01 -1.62572170e-01  7.01402287e-01  1.23289506e+00\n",
      "  -7.46519486e-01]\n",
      " [ 1.61634650e+00 -3.97860866e-01  1.29084425e+00  1.53012147e-01\n",
      "   1.33955643e+00  8.04001573e-01  1.13717335e+00 -2.97522513e-01\n",
      "   6.22375504e-01  4.91839937e-01  4.87063119e-01  7.94658511e-02\n",
      "   1.80943607e+00]\n",
      " [-1.19806288e+00  9.26818123e-01 -1.29691881e+00 -1.37465458e-01\n",
      "  -9.20854603e-01 -4.54917499e-01 -3.61885465e-01  1.54270932e-02\n",
      "   4.50435190e-01 -1.62638873e+00 -1.13086553e-01  6.35335351e-01\n",
      "  -5.67270655e-01]\n",
      " [ 5.15055875e-01  1.34790813e+00  4.28256562e-01  1.02444496e+00\n",
      "   1.06604959e-01 -7.69647267e-01 -1.25132703e+00  4.84851502e-01\n",
      "  -3.40490256e-01  9.65427646e-01 -1.09904673e+00 -1.43527854e+00\n",
      "   5.01419852e-02]\n",
      " [-1.67528882e+00 -8.97905253e-01  1.21896194e+00  1.53012147e-01\n",
      "  -4.41373474e-01  7.09582643e-01  9.17311387e-01 -6.10472119e-01\n",
      "   1.51646514e+00 -1.03655676e+00  1.55169482e-02  9.27166839e-01\n",
      "  -1.82217611e-01]\n",
      " [ 4.66109624e-01  1.63592480e-01 -3.89784341e-02  1.53012147e-01\n",
      "  -7.83859995e-01 -1.39910680e+00 -1.50117016e+00  1.54270932e-02\n",
      "  -1.66443068e+00  2.33519368e-01 -1.09904673e+00 -1.70675424e-01\n",
      "   1.49724669e-01]\n",
      " [ 6.37421500e-01 -4.94360660e-01  8.95491559e-01  1.53012147e-01\n",
      "  -3.04378866e-01  3.79116386e-01  6.07505900e-01 -6.88709520e-01\n",
      "   8.93605295e-02 -6.61991936e-01  7.01402287e-01  1.70538414e+00\n",
      "   3.65487151e-01]\n",
      " [ 6.37421500e-01  6.54864158e-01  9.31432712e-01  1.31492256e+00\n",
      "   1.54504835e+00 -1.39910680e+00 -4.31841543e-01 -1.15813393e+00\n",
      "  -6.15594759e-01  1.52512221e+00 -1.57059290e+00 -1.79659371e+00\n",
      "  -7.79713714e-01]\n",
      " [ 5.27292437e-01  1.28649917e+00 -8.65624966e-01 -1.95560979e-01\n",
      "  -7.15362691e-01  2.53224479e-01  6.77461977e-01 -7.66946921e-01\n",
      "  -2.20132036e-01 -3.34785882e-01 -1.98822220e-01  5.65851664e-01\n",
      "   9.96177483e-01]\n",
      " [-2.55847564e-01  9.26818123e-01 -1.36880112e+00 -1.00889827e+00\n",
      "  -1.40033573e+00 -1.03716757e+00 -7.51640756e-01  4.84851502e-01\n",
      "  -1.33774408e+00 -7.13656050e-01 -1.09904673e+00 -6.57061237e-01\n",
      "  -1.20459983e+00]\n",
      " [ 7.96496813e-01 -4.94360660e-01  1.21896194e+00 -6.60325146e-01\n",
      "   7.91578001e-01  8.82684015e-01  9.07317662e-01 -5.32234717e-01\n",
      "  -2.54520099e-01  9.65427646e-01  1.38728763e+00  3.99090814e-01\n",
      "   1.90901875e+00]\n",
      " [-5.61761627e-01  4.95472693e-02 -6.85919198e-01  4.43489751e-01\n",
      "  -8.52357299e-01  4.10589363e-01  2.67719236e-01 -8.45184323e-01\n",
      "  -6.67176853e-01 -1.31640404e+00 -2.41690054e-01  2.60123439e-01\n",
      "  -1.36061270e+00]\n",
      " [-1.92002007e+00 -1.43304047e+00  5.00138869e-01  4.43489751e-01\n",
      "  -8.52357299e-01  3.00433944e-01  7.88237497e-03  4.06614101e-01\n",
      "  -2.88908162e-01 -8.51427020e-01  6.15666620e-01 -3.93023224e-01\n",
      "  -9.98795619e-01]\n",
      " [-1.10017038e+00 -1.09090484e+00  5.36080023e-01  1.31492256e+00\n",
      "  -1.53733034e+00 -4.54917499e-01 -4.21847818e-01  2.50139298e-01\n",
      "  -3.57684288e-01 -1.23029719e+00  1.51589113e+00  1.76743014e-01\n",
      "  -3.48188751e-01]\n",
      " [ 1.07793775e+00 -8.97905253e-01 -3.26507663e-01 -1.00889827e+00\n",
      "  -1.67384257e-01  1.08725836e+00  1.14716707e+00 -1.15813393e+00\n",
      "   4.16047127e-01  9.30984904e-01  2.29856117e-01  1.33017223e+00\n",
      "   1.02937171e+00]\n",
      " [-1.10017038e+00 -8.62814418e-01  5.00138869e-01  8.79206158e-01\n",
      "  -1.12634652e+00  4.26325851e-01  2.87706686e-01  4.84851502e-01\n",
      "  -9.76669419e-01 -9.28923190e-01 -1.13086553e-01  8.29889676e-01\n",
      "  -1.16144734e+00]\n",
      " [ 1.48174431e+00 -6.87360248e-01  4.28256562e-01 -8.63659469e-01\n",
      "   5.17588784e-01  1.59082599e+00  1.92667765e+00 -3.75759914e-01\n",
      "   4.33241158e-01  1.56817564e+00  1.17294846e+00  3.15710389e-01\n",
      "   3.13720519e+00]\n",
      " [ 1.60195561e-01 -1.19617734e+00 -2.37515342e+00 -1.29937588e+00\n",
      "  -1.53733034e+00  1.08725836e+00  1.17714825e+00 -8.45184323e-01\n",
      "   1.15539048e+00  1.04359084e-01  7.01402287e-01  8.15992939e-01\n",
      "  -7.73074869e-01]\n",
      " [-7.94256315e-01 -1.11722297e+00 -2.90566509e-01 -1.00889827e+00\n",
      "   3.81076551e-02 -3.76235057e-01 -9.11540363e-01  2.04959953e+00\n",
      "  -2.05989340e+00 -7.69625506e-01  1.25868412e+00 -1.28241442e+00\n",
      "  -1.82217611e-01]\n",
      " [ 5.15055875e-01  1.95322502e+00  1.79402040e+00  1.60540017e+00\n",
      "   7.91578001e-01 -4.86390476e-01 -1.04145879e+00 -7.66946921e-01\n",
      "  -8.56311199e-01  1.48206878e+00 -1.22765023e+00 -9.34995987e-01\n",
      "  -3.48188751e-01]\n",
      " [-2.55847564e-01  1.44564352e-02 -2.90566509e-01  7.77334435e-03\n",
      "  -9.89351907e-01 -1.41484329e+00 -1.49117644e+00  8.76038509e-01\n",
      "  -1.66443068e+00  2.08481635e+00 -1.65632857e+00 -1.33800137e+00\n",
      "  -8.79296398e-01]\n",
      " [ 9.80045250e-01  3.39046651e-01 -2.18684202e-01  7.33967356e-01\n",
      "  -7.15362691e-01 -1.47778925e+00 -1.32128310e+00  3.28376699e-01\n",
      "  -9.93863450e-01  1.94704581e+00 -1.09904673e+00 -1.26851769e+00\n",
      "  -3.97980093e-01]\n",
      " [-6.84127253e-01 -6.69814831e-01 -6.14036891e-01  8.79206158e-01\n",
      "   5.17588784e-01 -4.54917499e-01  8.78321783e-02 -2.19285111e-01\n",
      "   3.39037239e-03 -1.29057199e+00  4.44195285e-01  5.10264714e-01\n",
      "  -1.29422425e+00]\n",
      " [-7.45310065e-01 -1.02072317e+00  7.15785791e-01 -3.98895302e-01\n",
      "  -1.67384257e-01  2.06015014e-01  6.47480801e-01  1.54270932e-02\n",
      "   8.11509850e-01 -1.97014913e-01  1.00147712e+00 -4.06919962e-01\n",
      "  -1.88856456e-01]\n",
      " [-1.10017038e+00 -4.76815243e-01 -1.46801895e-01 -2.82704260e-01\n",
      "  -1.33183843e+00 -1.08437704e+00 -5.01797621e-01  1.18898812e+00\n",
      "   5.49724667e-02 -1.14419033e+00  5.29930952e-01 -4.48610174e-01\n",
      "  -8.46102170e-01]\n",
      " [ 7.10840875e-01 -5.64542328e-01  3.56374255e-01  2.98250949e-01\n",
      "   1.06556722e+00  1.05578539e+00  7.77399232e-01 -1.31460873e+00\n",
      "   1.44768901e+00  5.13366651e-01  1.01252616e-01  6.07541876e-01\n",
      "   1.27832842e+00]\n",
      " [ 1.27372275e+00 -6.08405871e-01 -5.42154584e-01 -1.00889827e+00\n",
      "  -3.04378866e-01  5.67954247e-01  3.27681588e-01 -8.45184323e-01\n",
      "   6.39569535e-01 -1.53961484e-01  3.58459618e-01  1.38575918e+00\n",
      "   9.96177483e-01]\n",
      " [-7.45310065e-01 -6.52269414e-01 -2.18684202e-01  1.46016137e+00\n",
      "  -8.52357299e-01 -1.08714754e-01  4.47606293e-01  2.50139298e-01\n",
      "   5.02017284e-01 -1.26473993e+00 -2.84557887e-01  2.60123439e-01\n",
      "  -1.30418252e+00]\n",
      " [ 2.21378374e-01  1.04963604e+00 -7.57801505e-01  4.43489751e-01\n",
      "   1.06604959e-01 -1.24174192e+00 -1.45120153e+00  4.84851502e-01\n",
      "  -5.29624602e-01 -4.55335481e-01 -1.52772506e+00 -1.26851769e+00\n",
      "   3.15695809e-01]\n",
      " [ 7.35314000e-01 -6.25951288e-01 -3.03728058e-03 -1.08417697e-01\n",
      "   3.80594176e-01  8.98420503e-01  1.18714197e+00 -1.15813393e+00\n",
      "   5.87987441e-01  7.93213934e-01  5.72798786e-01  3.99090814e-01\n",
      "   2.58950043e+00]\n",
      " [ 9.43335563e-01 -5.64542328e-01  1.76668487e-01 -1.00889827e+00\n",
      "  -7.83859995e-01  4.89271805e-01  7.57411781e-01 -6.10472119e-01\n",
      "   3.47271001e-01  2.33519368e-01  8.30005788e-01  4.26884289e-01\n",
      "   1.94221298e+00]\n",
      " [ 1.10241088e+00 -4.24178992e-01  8.23609251e-01 -1.29937588e+00\n",
      "   3.81076551e-02  1.51214355e+00  1.55690981e+00 -1.54932094e+00\n",
      "   1.58136655e-01  1.60328541e-01 -3.27425721e-01  1.34406896e+00\n",
      "   1.19534285e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the StandardScaler class\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler on the features from the training set and transform it\n",
    "wX_train = sc.fit_transform(wX_train)\n",
    "\n",
    "# Apply the transform to the test set\n",
    "wX_test = sc.transform(wX_test)\n",
    "\n",
    "# Print the scaled training and test datasets\n",
    "print(wX_train)\n",
    "print(wX_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
